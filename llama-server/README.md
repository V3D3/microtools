# Setup
Clone and follow the steps in https;//github.com/aggiee/llama-v2-mps. Please use the 7b-chat model (edit `chat-server-flask.py` if you want a different one).
Ensure you have `flask` and `streamlit` installed.
Copy over the files here into the root of the cloned `llama-v2-mps` repo.

# Running
Run `serve.sh`, streamlit should open a browser window with the chat page running.
